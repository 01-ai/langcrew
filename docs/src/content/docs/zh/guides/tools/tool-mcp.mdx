---
title: MCP 集成
description: 学习如何将模型上下文协议（MCP）服务器与 LangCrew 智能体集成
---

## 什么是 MCP？

**模型上下文协议（Model Context Protocol，MCP）** 是一个开放标准，用于在大型语言模型和数据源之间建立安全连接。MCP 服务器提供工具和资源，智能体可以使用它们访问外部系统、API 和数据源。

## 为什么在 LangCrew 中使用 MCP？

LangCrew 中的 MCP 集成提供：

- ** 标准化连接** - 连接到任何兼容 MCP 的服务器
- ** 安全访问** - 内置安全和权限控制  
- ** 多种传输方式** - 支持 SSE、HTTP 流和 stdio
- ** 工具过滤** - 控制智能体可以访问哪些工具
- ** 易于扩展** - 无需代码更改即可添加新功能

## 支持的传输类型

LangCrew 支持三种 MCP 传输方法：

### 1. 服务器发送事件（SSE）
最适合实时数据和实时更新：

```python
server_config = {
    "url": "https://api.example.com/mcp/sse?key=your_key",
    "transport": "sse"
}
```

### 2. 流式 HTTP
适用于 REST API 集成：

```python
server_config = {
    "url": "https://api.example.com/mcp",
    "transport": "streamable_http"
}
```

### 3. 标准输入输出（stdio）
完美适用于本地工具和脚本：

```python
server_config = {
    "command": "python3",
    "args": ["path/to/your/tool.py"],
    "transport": "stdio"
}
```

## 基本用法

### 1. 配置 MCP 服务器

定义您的 MCP 服务器配置：

```python
from langcrew import Agent

# 配置您的 MCP 服务器
mcp_server_configs = {
    "my_server": {
        "url": "https://api.example.com/mcp",
        "transport": "streamable_http"
    }
}
```

### 2. 创建带 MCP 的智能体

将 MCP 服务器添加到您的智能体：

```python
@agent
def my_agent(self) -> Agent:
    return Agent(
        config=self.agents_config["my_agent"],
        mcp_servers=mcp_server_configs,
        llm=self._get_default_llm(),
        verbose=True
    )
```

### 3. 可选：过滤可用工具

控制智能体可以访问哪些工具：

```python
@agent
def restricted_agent(self) -> Agent:
    return Agent(
        config=self.agents_config["my_agent"],
        mcp_servers=mcp_server_configs,
        mcp_tool_filter=["search", "calculator"],  # 只有这些工具
        llm=self._get_default_llm()
    )
```

## 完整示例

这是一个使用不同 MCP 传输类型的完整工作示例：

```python
import os
from langchain_openai import ChatOpenAI
from langcrew import Agent, CrewBase, agent, task, crew
from langcrew.task import Task
from langcrew.crew import Crew

@CrewBase
class MyCrew:
    agents_config = "config/agents.yaml"
    tasks_config = "config/tasks.yaml"

    def _get_default_llm(self):
        return ChatOpenAI(
            model="gpt-4o-mini", 
            temperature=0.1, 
            api_key=os.getenv("OPENAI_API_KEY")
        )

    @agent
    def web_agent(self) -> Agent:
        # SSE 传输用于实时数据
        server_config = {
            "url": f"https://api.example.com/sse?key={os.getenv('API_KEY')}",
            "transport": "sse"
        }
        return Agent(
            config=self.agents_config["web_agent"],
            mcp_servers={"web_server": server_config},
            llm=self._get_default_llm()
        )

    @agent  
    def calculator_agent(self) -> Agent:
        # stdio 传输用于本地工具
        current_dir = os.path.dirname(os.path.abspath(__file__))
        calc_script = os.path.join(current_dir, "tools", "calculator.py")
        
        server_config = {
            "command": "python3",
            "args": [calc_script],
            "transport": "stdio"
        }
        return Agent(
            config=self.agents_config["calculator"],
            mcp_servers={"calc_server": server_config},
            mcp_tool_filter=["add", "multiply"],  # 限制工具
            llm=self._get_default_llm()
        )

    @task
    def web_search_task(self) -> Task:
        return Task(
            config=self.tasks_config["web_search"],
            agent=self.web_agent()
        )

    @task
    def calculation_task(self) -> Task:
        return Task(
            config=self.tasks_config["calculation"],
            agent=self.calculator_agent()
        )

    @crew
    def crew(self) -> Crew:
        return Crew(
            agents=self.agents,
            tasks=self.tasks,
            verbose=True
        )
```