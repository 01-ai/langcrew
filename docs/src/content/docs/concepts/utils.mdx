---
title: Utils
description: Understanding Utils - utility functions for AI agent development
---

Utils provides a collection of utility functions and helper tools for AI agent development, including file detection, token counting, language processing, and message handling utilities.

## What is Utils?

Utils in langcrew provides:
- **File Detection**: Intelligent file type detection and encoding analysis
- **Token Counting**: Precise token counting for GPT and Claude models
- **Language Detection**: Simple language identification (Chinese/English)
- **Message Utilities**: Message ID generation and handling helpers

## Core Architecture

Utils is organized as independent utility modules, each serving specific purposes:

```python
from langcrew.utils import (
    is_binary_file, is_text_file,      # File detection
    TokenCounter,                       # Token counting
    detect_chinese, detect_language,    # Language detection
    generate_message_id                 # Message utilities
)
```

## Key Components

### File Detection
Intelligent file type detection using multiple heuristic rules for binary/text classification.

**Key Features:**
- Binary vs text file detection
- UTF-8/UTF-16 encoding validation
- File signature recognition
- Chinese text support
- Encoding detection

```python
from langcrew.utils.file_detect import is_binary_file, is_text_file

# Detect file types
with open('document.pdf', 'rb') as f:
    data = f.read()
    is_binary = is_binary_file(data)  # True
    is_text = is_text_file(data)      # False

# File type hints
from langcrew.utils.file_detect import get_file_type_hint
file_type = get_file_type_hint(data)  # "binary" or "text"
```

**Detection Rules:**
1. Null bytes presence (most reliable)
2. Common binary file signatures
3. UTF-8/UTF-16 encoding validation
4. Control character ratio analysis
5. Chinese character pattern support

| Function | Purpose | Parameters |
|----------|---------|------------|
| `is_binary_file(data)` | Detect binary files | `data: bytes \| bytearray` |
| `is_text_file(data)` | Detect text files | `data: bytes \| bytearray` |
| `get_file_type_hint(data)` | Get file type hint | `data: bytes \| bytearray` |

### Token Counting
Precise token counting for LLM models with support for GPT and Claude.

**Key Features:**
- GPT-4 exact token counting
- Claude token estimation
- Message-based counting
- Token limit constants
- Model-specific encoding

```python
from langcrew.utils.token_counter import TokenCounter
from langchain_core.messages import HumanMessage

# Initialize counter
counter = TokenCounter(model_name="gpt-4")

# Count tokens in messages
messages = [HumanMessage(content="Hello, how are you?")]
token_count, is_exact = counter.count_messages(messages)
print(f"Tokens: {token_count}, Exact: {is_exact}")
```

**Constants:**
- `TOKEN_LIMIT = 64000` - Unified token limit for truncation
- `MAX_TOKEN_LIMIT = 150000` - Maximum token limit for user context

| Method | Purpose | Returns |
|--------|---------|---------|
| `count_messages(messages)` | Count tokens in message list | `tuple[int, bool]` |
| `_count_gpt_tokens(messages)` | Exact GPT token counting | `int` |
| `_estimate_claude_tokens(messages)` | Estimate Claude tokens | `int` |

### Language Detection
Simple language identification focusing on Chinese and English text.

**Key Features:**
- Chinese character detection
- Character ratio analysis
- Simple and fast processing
- Unicode range support

```python
from langcrew.utils.language import detect_chinese, detect_language

# Detect Chinese text
is_chinese = detect_chinese("你好世界")  # True
is_chinese = detect_chinese("Hello World")  # False

# General language detection
language = detect_language("你好世界")  # "zh"
language = detect_language("Hello World")  # "en"
```

**Detection Logic:**
- Chinese characters: Unicode range `\u4e00-\u9fff`
- Threshold: 30% Chinese characters = Chinese text
- Fallback: English for non-Chinese text

| Function | Purpose | Parameters | Returns |
|----------|---------|------------|---------|
| `detect_chinese(text)` | Detect Chinese text | `text: str` | `bool` |
| `detect_language(text)` | Detect language | `text: str` | `str` ("zh"/"en") |

### Message Utilities
Helper functions for message ID generation and message handling.

**Key Features:**
- Unique message ID generation
- Timestamp-based IDs
- Collision avoidance
- High concurrency support

```python
from langcrew.utils.message_utils import generate_message_id

# Generate unique message ID
msg_id = generate_message_id()
# Format: "1748438204041_a7k9" (timestamp_randomsuffix)
```

**ID Format:**
- Timestamp: Milliseconds since epoch
- Suffix: 4-character random string (lowercase + digits)
- Example: `1748438204041_a7k9`

| Function | Purpose | Returns |
|----------|---------|---------|
| `generate_message_id()` | Generate unique message ID | `str` |

## Usage Patterns

### File Processing Pipeline
```python
from langcrew.utils.file_detect import is_binary_file, get_file_type_hint

def process_file(file_path):
    with open(file_path, 'rb') as f:
        data = f.read()
    
    if is_binary_file(data):
        return f"Binary file: {get_file_type_hint(data)}"
    else:
        # Process as text
        text_content = data.decode('utf-8')
        return f"Text file: {len(text_content)} characters"
```

### Token Management
```python
from langcrew.utils.token_counter import TokenCounter, TOKEN_LIMIT

def manage_context(messages, model_name="gpt-4"):
    counter = TokenCounter(model_name)
    token_count, _ = counter.count_messages(messages)
    
    if token_count > TOKEN_LIMIT:
        # Truncate messages to fit limit
        return messages[-10:]  # Keep last 10 messages
    
    return messages
```

### Multi-language Support
```python
from langcrew.utils.language import detect_language

def get_response_template(user_input):
    lang = detect_language(user_input)
    
    if lang == "zh":
        return "我理解了您的问题："
    else:
        return "I understand your question:"
```

## When to Use Utils

- **File processing applications** requiring intelligent file type detection
- **Token-aware applications** needing precise token counting for LLM usage
- **Multi-language applications** requiring simple language detection
- **Message-based systems** needing unique ID generation
- **Agent development** requiring common utility functions

## Next Steps

- **[Utils Quick Start](/guides/utils/getting-started)** - Get started in 5 minutes
- **[Practical Examples](/guides/utils/examples)** - Real-world usage examples
- **[Advanced Configuration](/guides/utils/configuration)** - Advanced utility configuration