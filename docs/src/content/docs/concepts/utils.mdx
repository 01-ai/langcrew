---
title: Utils
description: Understanding Utils - utility functions and helpers for AI workflows
---

Utils provides essential utility functions and helpers that support AI workflows, offering practical tools for file handling, token management, language processing, and message operations.

## What is Utils?

Utils in langcrew provides:
- **File detection**: Intelligent file type detection with content analysis and binary/text classification
- **Token counting**: Precise token counting for OpenAI, Anthropic, and other LLM models
- **Language detection**: Simple language identification for text processing
- **Message utilities**: Helper functions for message ID generation and formatting

## Core Architecture

Utils is a collection of standalone utility modules that can be used independently:

```python
from langcrew.utils import detect_file_type, count_tokens, detect_language

# File detection
file_info = detect_file_type("document.pdf")

# Token counting
tokens = count_tokens("Hello, world!", model="gpt-4")

# Language detection
language = detect_language("Hello, how are you?")
```

## Key Components

### File Detection
Intelligent file type detection using binary signatures, content analysis, and encoding detection.

```python
from langcrew.utils.file_detect import detect_file_type

# Detect file type with content analysis
file_info = detect_file_type("document.pdf")
print(file_info.file_type)    # File extension
print(file_info.mime_type)    # MIME type
print(file_info.is_binary)    # True/False for binary detection
print(file_info.size)         # File size in bytes
```

#### File Detection Parameters

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `file_path` | str | Path to file for detection | Required |
| `read_content` | bool | Whether to read file content | True |
| `extract_metadata` | bool | Extract detailed metadata | True |

### Token Counter
Precise token counting using tiktoken for GPT models and approximation for other models.

```python
from langcrew.utils.token_counter import TokenCounter

# Create token counter for specific model
counter = TokenCounter(model_name="gpt-4")

# Count tokens in text
tokens = counter.count_text("Hello, world!")

# Count tokens in messages (with exact/approximate indicator)
messages = [
    {"role": "user", "content": "Hello"},
    {"role": "assistant", "content": "Hi there!"}
]
token_count, is_exact = counter.count_messages(messages)
```

#### Token Counter Parameters

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `text` | str \| List[dict] | Text or messages to count | Required |
| `model` | str | Model name for tokenization | "gpt-4" |
| `include_metadata` | bool | Include token breakdown | False |

### Language Detection
Simple language detection focusing on Chinese vs. non-Chinese text classification.

```python
from langcrew.utils.language import detect_language, detect_chinese

# Basic language detection (primarily Chinese vs. English)
lang = detect_language("你好，世界！")
print(lang)  # "zh"

# Specific Chinese detection
is_chinese = detect_chinese("Hello, 世界！")
print(is_chinese)  # True (if >30% Chinese characters)
```

#### Language Detection Parameters

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `text` | str | Text for language detection | Required |
| `confidence_threshold` | float | Minimum confidence score | 0.8 |
| `return_confidence` | bool | Return confidence score | False |

### Message Utilities
Helper functions for generating unique message IDs and handling message operations.

```python
from langcrew.utils.message_utils import generate_message_id

# Generate unique message ID with timestamp and random suffix
msg_id = generate_message_id()
print(msg_id)  # Example: "1748438204041_a7k9"

# Use in web applications for message tracking
def create_message(content: str, role: str):
    return {
        "id": generate_message_id(),
        "content": content,
        "role": role,
        "timestamp": time.time()
    }
```

## Integration with langcrew

Utils integrates seamlessly with all langcrew components:

- **[Agents](/concepts/agents)**: Use token counting for prompt optimization
- **[Tasks](/concepts/tasks)**: File detection for document processing tasks
- **[Crews](/concepts/crews)**: Language detection for multi-language crews

```python
from langcrew import Agent
from langcrew.utils import count_tokens, detect_language

# Agent with token-aware prompts
agent = Agent(
    role="Content Analyzer",
    goal="Analyze content efficiently",
    backstory="Expert at processing various content types",
    tools=[detect_file_type, count_tokens]
)

# Use in task execution
def process_document(file_path: str):
    # Detect file type
    file_info = detect_file_type(file_path)
    
    # Count tokens if text file
    if file_info.is_text:
        tokens = count_tokens(file_info.content)
        print(f"Document has {tokens} tokens")
    
    # Detect language
    if file_info.content:
        language = detect_language(file_info.content)
        print(f"Document language: {language}")
```

## When to Use Utils

- **File processing** applications handling multiple formats
- **Token optimization** for cost-effective LLM usage
- **Multi-language** applications requiring language detection
- **Message processing** systems needing formatting utilities
- **Content analysis** workflows requiring metadata extraction

## Supported File Types

### Document Formats
- **Text**: .txt, .md, .rst, .log
- **Office**: .docx, .xlsx, .pptx
- **PDF**: .pdf (with text extraction)
- **Code**: .py, .js, .html, .css, .json, .xml

### Media Formats
- **Images**: .jpg, .png, .gif, .bmp, .svg
- **Audio**: .mp3, .wav, .flac, .ogg
- **Video**: .mp4, .avi, .mov, .wmv

### Archive Formats
- **Compressed**: .zip, .rar, .7z, .tar, .gz

## Supported Models for Token Counting

### OpenAI Models
- GPT-4, GPT-4 Turbo, GPT-4o
- GPT-3.5 Turbo variants
- Text-embedding models

### Anthropic Models
- Claude-3 (Opus, Sonnet, Haiku)
- Claude-2 variants

### Other Models
- Llama 2/3 variants
- Mistral models
- Custom tokenizers

## Next Steps

- **[Utils Quick Start](/guides/utils/getting-started)** - Get started in 5 minutes
- **[Utils Configuration](/guides/utils/configuration)** - Complete configuration guide
- **Examples** - Check `examples/components/utils/` for real-world implementations